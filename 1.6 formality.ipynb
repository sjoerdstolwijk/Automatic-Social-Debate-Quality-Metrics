{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "\n",
    "path = 'C:/Users/shrim/Desktop/Research/Social Media Analysis/publicsphere'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load comments content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{path}/data/sample/Data_ReadyForAnalysis_WithComments&MetaInfo.csv') # change file here\n",
    "data = df[['ID','commentText']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_no_stemming(text):\n",
    "    unstemmed = re.sub(' +',' ',' '.join([re.sub(r'http\\S+|[^a-zA-Z0-9@]|\\'', ' '\n",
    "                                                 , w.lower()) for w in str(text).split()]).strip())\n",
    "    return unstemmed\n",
    "\n",
    "def processing_w_stemming(text):\n",
    "    # define stemmer\n",
    "    ps = PorterStemmer()\n",
    "    stemmed = re.sub(' +',' ',' '.join([ps.stem(re.sub(r'http\\S+|[^a-zA-Z0-9@]|\\'',' '\n",
    "                                               , w.lower())) for w in str(text).split()]).strip())\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming\n",
    "data['CommentsStemmed'] = data['commentText'].apply(lambda row: processing_w_stemming(row))\n",
    "\n",
    "# Produce another column with comments not stemmed, but processed:\n",
    "data['CommentsNonStemmed'] = data['commentText'].apply(lambda row: processing_no_stemming(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and POS tagging\n",
    "\n",
    "Please note that the POS are tagged by the universal tagset to align with the formality score equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "data['tokens'] = data['CommentsNonStemmed'].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "#POS tagging\n",
    "data['POS'] = data['tokens'].apply(lambda x: pos_tag(x, tagset = \"universal\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating language formality\n",
    "\n",
    "\n",
    "Calculating the formality scores using nouns, adjectives, articles and prepositions versus pronouns, adverbs, verbs and interjections.\n",
    "\n",
    "The equation, using corresponding tags in the NLTK's universal POS Tagset, is as the following:\n",
    "\n",
    "<font size = \"3\"><center> $\\frac{{{NOUN}+{ADJ}+{DET}+{PRT}-{PRON}-{ADV}-{VERB}-{CONJ}}+100}{2}$ </center></font> \n",
    "(Heylighen & Dewaele, 2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     {'ADV': 3, 'NOUN': 8, 'VERB': 5, 'DET': 5, 'AD...\n",
       "1     {'NOUN': 16, 'VERB': 11, 'ADV': 8, 'ADP': 9, '...\n",
       "2                                           {'NOUN': 2}\n",
       "3            {'DET': 1, 'NOUN': 2, 'VERB': 3, 'ADV': 1}\n",
       "4                       {'ADP': 1, 'NUM': 1, 'NOUN': 1}\n",
       "5     {'NOUN': 10, 'VERB': 14, 'DET': 3, 'PRON': 6, ...\n",
       "6     {'NOUN': 10, 'VERB': 14, 'DET': 3, 'PRON': 6, ...\n",
       "7     {'ADJ': 2, 'NOUN': 21, 'ADP': 12, 'DET': 16, '...\n",
       "8     {'NOUN': 8, 'PRON': 3, 'VERB': 4, 'CONJ': 1, '...\n",
       "9     {'PRON': 2, 'VERB': 2, 'ADJ': 3, 'DET': 3, 'NO...\n",
       "10    {'PRON': 2, 'VERB': 2, 'ADJ': 3, 'DET': 3, 'NO...\n",
       "11    {'PRON': 1, 'VERB': 2, 'DET': 2, 'NOUN': 4, 'A...\n",
       "12    {'PRON': 1, 'VERB': 2, 'DET': 2, 'NOUN': 4, 'A...\n",
       "13    {'NOUN': 5, 'VERB': 2, 'ADV': 1, 'ADP': 1, 'DE...\n",
       "14    {'PRON': 4, 'VERB': 6, 'DET': 4, 'ADJ': 2, 'NO...\n",
       "15            {'VERB': 2, 'ADJ': 1, 'ADV': 1, 'PRT': 1}\n",
       "16    {'DET': 8, 'NOUN': 11, 'VERB': 9, 'ADJ': 5, 'A...\n",
       "17    {'DET': 8, 'NOUN': 11, 'VERB': 9, 'ADJ': 5, 'A...\n",
       "18    {'NOUN': 2, 'VERB': 1, 'PRON': 1, 'ADP': 2, 'P...\n",
       "19                                {'NOUN': 1, 'ADV': 2}\n",
       "Name: POS_count, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Count of POS per row\n",
    "data['POS_count'] = data['POS'].apply(lambda x: nltk.FreqDist(tag for (word, tag) in x))\n",
    "\n",
    "data['POS_count'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating formality score\n",
    "numerator = ['NOUN','ADJ','DET','PRT']\n",
    "denominator = ['PRON','ADV','VERB','CONJ']\n",
    "\n",
    "#Insert formality column with value 0 \n",
    "data['formality'] = 0\n",
    "\n",
    "for i in range(len(data)):\n",
    "    num_temp = 0\n",
    "    den_temp = 0\n",
    "    \n",
    "    for tag in range(3):\n",
    "        num_temp += data['POS_count'][i][numerator[tag]]\n",
    "        den_temp += data['POS_count'][i][denominator[tag]]\n",
    "        \n",
    "        formality_score = (num_temp - den_temp +100)/2\n",
    "        \n",
    "        data['formality'][i] = formality_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing scores\n",
    "\n",
    "Like other deliberative qualities, both dummy and sum rationality scores are used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>commentText</th>\n",
       "      <th>CommentsStemmed</th>\n",
       "      <th>CommentsNonStemmed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS_count</th>\n",
       "      <th>formality</th>\n",
       "      <th>TopicRelevance</th>\n",
       "      <th>Reasoning</th>\n",
       "      <th>BackgroundInfo</th>\n",
       "      <th>ExternalEvidence</th>\n",
       "      <th>ExternalEvidence_1_TEXT</th>\n",
       "      <th>rationality_score</th>\n",
       "      <th>dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UgwtCALfP60D8ZvhHOp4AaABAg</td>\n",
       "      <td>Only thing needed is the roasts of the fuckers...</td>\n",
       "      <td>onli thing need is the roast of the fucker tha...</td>\n",
       "      <td>only thing needed is the roasts of the fuckers...</td>\n",
       "      <td>[only, thing, needed, is, the, roasts, of, the...</td>\n",
       "      <td>[(only, ADV), (thing, NOUN), (needed, VERB), (...</td>\n",
       "      <td>{'ADV': 3, 'NOUN': 8, 'VERB': 5, 'DET': 5, 'AD...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ugw2XXTMmSzbW49HvD14AaABAg.8v7l4MgiomY8v7oDw3r2nq</td>\n",
       "      <td>Saehar Bokhari how about u expand on that, bec...</td>\n",
       "      <td>saehar bokhari how about u expand on that beca...</td>\n",
       "      <td>saehar bokhari how about u expand on that beca...</td>\n",
       "      <td>[saehar, bokhari, how, about, u, expand, on, t...</td>\n",
       "      <td>[(saehar, NOUN), (bokhari, VERB), (how, ADV), ...</td>\n",
       "      <td>{'NOUN': 16, 'VERB': 11, 'ADV': 8, 'ADP': 9, '...</td>\n",
       "      <td>54.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ugiz8nfgau9byHgCoAEC</td>\n",
       "      <td>Pure evil</td>\n",
       "      <td>pure evil</td>\n",
       "      <td>pure evil</td>\n",
       "      <td>[pure, evil]</td>\n",
       "      <td>[(pure, NOUN), (evil, NOUN)]</td>\n",
       "      <td>{'NOUN': 2}</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ugiw24w2DD-8EXgCoAEC</td>\n",
       "      <td>the beek didn't even apologize. amazing</td>\n",
       "      <td>the beek didn t even apologize amaz</td>\n",
       "      <td>the beek didn t even apologize amazing</td>\n",
       "      <td>[the, beek, didn, t, even, apologize, amazing]</td>\n",
       "      <td>[(the, DET), (beek, NOUN), (didn, NOUN), (t, V...</td>\n",
       "      <td>{'DET': 1, 'NOUN': 2, 'VERB': 3, 'ADV': 1}</td>\n",
       "      <td>49.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UggcaoEIJpYwe3gCoAEC</td>\n",
       "      <td>Under 301 club!</td>\n",
       "      <td>under 301 club</td>\n",
       "      <td>under 301 club</td>\n",
       "      <td>[under, 301, club]</td>\n",
       "      <td>[(under, ADP), (301, NUM), (club, NOUN)]</td>\n",
       "      <td>{'ADP': 1, 'NUM': 1, 'NOUN': 1}</td>\n",
       "      <td>50.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221</th>\n",
       "      <td>UgynUnOlxIjSh3ARy4F4AaABAg.8pMRfMuIMsc8pMahcyl8w-</td>\n",
       "      <td>@LAST CALL Oh that's what you use yourself?</td>\n",
       "      <td>@last call oh that what you use yourself</td>\n",
       "      <td>@last call oh that s what you use yourself</td>\n",
       "      <td>[@, last, call, oh, that, s, what, you, use, y...</td>\n",
       "      <td>[(@, NOUN), (last, ADJ), (call, NOUN), (oh, VE...</td>\n",
       "      <td>{'NOUN': 2, 'ADJ': 1, 'VERB': 3, 'ADP': 1, 'PR...</td>\n",
       "      <td>48.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>UgwhaLzvJAORa5kfved4AaABAg</td>\n",
       "      <td>ABC is owned by the Bilderberg Group.</td>\n",
       "      <td>abc is own by the bilderberg group</td>\n",
       "      <td>abc is owned by the bilderberg group</td>\n",
       "      <td>[abc, is, owned, by, the, bilderberg, group]</td>\n",
       "      <td>[(abc, NOUN), (is, VERB), (owned, VERB), (by, ...</td>\n",
       "      <td>{'NOUN': 3, 'VERB': 2, 'ADP': 1, 'DET': 1}</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3223</th>\n",
       "      <td>UgwNbLpnlTffTnh9dTJ4AaABAg</td>\n",
       "      <td>lol both these guys look like brothers . One i...</td>\n",
       "      <td>lol both these guy look like brother one is mu...</td>\n",
       "      <td>lol both these guys look like brothers one is ...</td>\n",
       "      <td>[lol, both, these, guys, look, like, brothers,...</td>\n",
       "      <td>[(lol, ADJ), (both, DET), (these, DET), (guys,...</td>\n",
       "      <td>{'ADJ': 4, 'DET': 2, 'NOUN': 3, 'VERB': 3, 'AD...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3224</th>\n",
       "      <td>Ugy7xo56npDOiGcxqNp4AaABAg.8e5xq7bbujt8e8VLuajhuv</td>\n",
       "      <td>yeah no one seems to remember he said that.......</td>\n",
       "      <td>yeah no one seem to rememb he said that i reme...</td>\n",
       "      <td>yeah no one seems to remember he said that i r...</td>\n",
       "      <td>[yeah, no, one, seems, to, remember, he, said,...</td>\n",
       "      <td>[(yeah, ADV), (no, DET), (one, NOUN), (seems, ...</td>\n",
       "      <td>{'ADV': 3, 'DET': 5, 'NOUN': 5, 'VERB': 9, 'PR...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3225</th>\n",
       "      <td>UgwrtxPq3mqkFUh95zt4AaABAg.8ttLClEZPSh8ttRa1ia67R</td>\n",
       "      <td>What crimes...yes there were some shady indivi...</td>\n",
       "      <td>what crimes y there were some shadi individu b...</td>\n",
       "      <td>what crimes yes there were some shady individu...</td>\n",
       "      <td>[what, crimes, yes, there, were, some, shady, ...</td>\n",
       "      <td>[(what, PRON), (crimes, VERB), (yes, ADV), (th...</td>\n",
       "      <td>{'PRON': 9, 'VERB': 20, 'ADV': 6, 'DET': 6, 'A...</td>\n",
       "      <td>49.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3226 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              commentId  \\\n",
       "0                            UgwtCALfP60D8ZvhHOp4AaABAg   \n",
       "1     Ugw2XXTMmSzbW49HvD14AaABAg.8v7l4MgiomY8v7oDw3r2nq   \n",
       "2                                  Ugiz8nfgau9byHgCoAEC   \n",
       "3                                  Ugiw24w2DD-8EXgCoAEC   \n",
       "4                                  UggcaoEIJpYwe3gCoAEC   \n",
       "...                                                 ...   \n",
       "3221  UgynUnOlxIjSh3ARy4F4AaABAg.8pMRfMuIMsc8pMahcyl8w-   \n",
       "3222                         UgwhaLzvJAORa5kfved4AaABAg   \n",
       "3223                         UgwNbLpnlTffTnh9dTJ4AaABAg   \n",
       "3224  Ugy7xo56npDOiGcxqNp4AaABAg.8e5xq7bbujt8e8VLuajhuv   \n",
       "3225  UgwrtxPq3mqkFUh95zt4AaABAg.8ttLClEZPSh8ttRa1ia67R   \n",
       "\n",
       "                                            commentText  \\\n",
       "0     Only thing needed is the roasts of the fuckers...   \n",
       "1     Saehar Bokhari how about u expand on that, bec...   \n",
       "2                                             Pure evil   \n",
       "3               the beek didn't even apologize. amazing   \n",
       "4                                       Under 301 club!   \n",
       "...                                                 ...   \n",
       "3221        @LAST CALL Oh that's what you use yourself?   \n",
       "3222              ABC is owned by the Bilderberg Group.   \n",
       "3223  lol both these guys look like brothers . One i...   \n",
       "3224  yeah no one seems to remember he said that.......   \n",
       "3225  What crimes...yes there were some shady indivi...   \n",
       "\n",
       "                                        CommentsStemmed  \\\n",
       "0     onli thing need is the roast of the fucker tha...   \n",
       "1     saehar bokhari how about u expand on that beca...   \n",
       "2                                             pure evil   \n",
       "3                   the beek didn t even apologize amaz   \n",
       "4                                        under 301 club   \n",
       "...                                                 ...   \n",
       "3221           @last call oh that what you use yourself   \n",
       "3222                 abc is own by the bilderberg group   \n",
       "3223  lol both these guy look like brother one is mu...   \n",
       "3224  yeah no one seem to rememb he said that i reme...   \n",
       "3225  what crimes y there were some shadi individu b...   \n",
       "\n",
       "                                     CommentsNonStemmed  \\\n",
       "0     only thing needed is the roasts of the fuckers...   \n",
       "1     saehar bokhari how about u expand on that beca...   \n",
       "2                                             pure evil   \n",
       "3                the beek didn t even apologize amazing   \n",
       "4                                        under 301 club   \n",
       "...                                                 ...   \n",
       "3221         @last call oh that s what you use yourself   \n",
       "3222               abc is owned by the bilderberg group   \n",
       "3223  lol both these guys look like brothers one is ...   \n",
       "3224  yeah no one seems to remember he said that i r...   \n",
       "3225  what crimes yes there were some shady individu...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0     [only, thing, needed, is, the, roasts, of, the...   \n",
       "1     [saehar, bokhari, how, about, u, expand, on, t...   \n",
       "2                                          [pure, evil]   \n",
       "3        [the, beek, didn, t, even, apologize, amazing]   \n",
       "4                                    [under, 301, club]   \n",
       "...                                                 ...   \n",
       "3221  [@, last, call, oh, that, s, what, you, use, y...   \n",
       "3222       [abc, is, owned, by, the, bilderberg, group]   \n",
       "3223  [lol, both, these, guys, look, like, brothers,...   \n",
       "3224  [yeah, no, one, seems, to, remember, he, said,...   \n",
       "3225  [what, crimes, yes, there, were, some, shady, ...   \n",
       "\n",
       "                                                    POS  \\\n",
       "0     [(only, ADV), (thing, NOUN), (needed, VERB), (...   \n",
       "1     [(saehar, NOUN), (bokhari, VERB), (how, ADV), ...   \n",
       "2                          [(pure, NOUN), (evil, NOUN)]   \n",
       "3     [(the, DET), (beek, NOUN), (didn, NOUN), (t, V...   \n",
       "4              [(under, ADP), (301, NUM), (club, NOUN)]   \n",
       "...                                                 ...   \n",
       "3221  [(@, NOUN), (last, ADJ), (call, NOUN), (oh, VE...   \n",
       "3222  [(abc, NOUN), (is, VERB), (owned, VERB), (by, ...   \n",
       "3223  [(lol, ADJ), (both, DET), (these, DET), (guys,...   \n",
       "3224  [(yeah, ADV), (no, DET), (one, NOUN), (seems, ...   \n",
       "3225  [(what, PRON), (crimes, VERB), (yes, ADV), (th...   \n",
       "\n",
       "                                              POS_count  formality  \\\n",
       "0     {'ADV': 3, 'NOUN': 8, 'VERB': 5, 'DET': 5, 'AD...       53.0   \n",
       "1     {'NOUN': 16, 'VERB': 11, 'ADV': 8, 'ADP': 9, '...       54.5   \n",
       "2                                           {'NOUN': 2}       51.0   \n",
       "3            {'DET': 1, 'NOUN': 2, 'VERB': 3, 'ADV': 1}       49.5   \n",
       "4                       {'ADP': 1, 'NUM': 1, 'NOUN': 1}       50.5   \n",
       "...                                                 ...        ...   \n",
       "3221  {'NOUN': 2, 'ADJ': 1, 'VERB': 3, 'ADP': 1, 'PR...       48.5   \n",
       "3222         {'NOUN': 3, 'VERB': 2, 'ADP': 1, 'DET': 1}       51.0   \n",
       "3223  {'ADJ': 4, 'DET': 2, 'NOUN': 3, 'VERB': 3, 'AD...       53.0   \n",
       "3224  {'ADV': 3, 'DET': 5, 'NOUN': 5, 'VERB': 9, 'PR...       50.0   \n",
       "3225  {'PRON': 9, 'VERB': 20, 'ADV': 6, 'DET': 6, 'A...       49.5   \n",
       "\n",
       "      TopicRelevance  Reasoning  BackgroundInfo  ExternalEvidence  \\\n",
       "0                  1          1               0                 0   \n",
       "1                  1          0               1                 0   \n",
       "2                  1          0               0                 0   \n",
       "3                  0          0               0                 0   \n",
       "4                  0          0               0                 0   \n",
       "...              ...        ...             ...               ...   \n",
       "3221               0          0               0                 0   \n",
       "3222               0          0               0                 0   \n",
       "3223               0          0               0                 0   \n",
       "3224               0          0               0                 0   \n",
       "3225               1          0               1                 0   \n",
       "\n",
       "     ExternalEvidence_1_TEXT  rationality_score  dummy  \n",
       "0                        NaN                  2      1  \n",
       "1                        NaN                  2      1  \n",
       "2                        NaN                  1      1  \n",
       "3                        NaN                  0      0  \n",
       "4                        NaN                  0      0  \n",
       "...                      ...                ...    ...  \n",
       "3221                     NaN                  0      0  \n",
       "3222                     NaN                  0      0  \n",
       "3223                     NaN                  0      0  \n",
       "3224                     NaN                  0      0  \n",
       "3225                     NaN                  2      1  \n",
       "\n",
       "[3226 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Getting manually coded score\n",
    "manual_rationality = df[['commentId','TopicRelevance','Reasoning','BackgroundInfo','ExternalEvidence','ExternalEvidence_1_TEXT']]\n",
    "\n",
    "#create rationality score by summing the 4 indicators \n",
    "manual_rationality['rationality_score'] = manual_rationality.sum(axis = 1, numeric_only=True)\n",
    "\n",
    "#create dummy variable\n",
    "manual_rationality['dummy'] = manual_rationality['rationality_score'].apply(lambda x: 0 if x==0 else 1)\n",
    "\n",
    "manual_rationality\n",
    "\n",
    "#merge dataframes\n",
    "data = data.merge(manual_rationality)\n",
    "data = data.drop_duplicates(subset=['commentId'], ignore_index = True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formality</th>\n",
       "      <th>rationality_score</th>\n",
       "      <th>dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>formality</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.203761</td>\n",
       "      <td>0.118002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rationality_score</th>\n",
       "      <td>0.203761</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.819416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>0.118002</td>\n",
       "      <td>0.819416</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   formality  rationality_score     dummy\n",
       "formality           1.000000           0.203761  0.118002\n",
       "rationality_score   0.203761           1.000000  0.819416\n",
       "dummy               0.118002           0.819416  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Correlation matrix\n",
    "data[['formality','rationality_score','dummy']].corr()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
