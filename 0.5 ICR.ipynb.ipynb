{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e5f56479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43b2babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load icr data:\n",
    "ICRdata4: pd.DataFrame = pd.read_spss('data/ICR/ICR_Round4-Online+user+comments+responding+to+satire+and+news+videos_January+12,+2021_11.16 (1).sav')\n",
    "ICRdata6: pd.DataFrame = pd.read_spss('data/ICR/ICR round 6.sav')\n",
    "#only keep codable comments:\n",
    "ICRdata4c = ICRdata4[ICRdata4['codable'] == 'Yes'].copy()\n",
    "ICRdata6c = ICRdata6[ICRdata6['codable'] == 'Yes'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1792202d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coder',\n",
       " 'ID',\n",
       " 'Mark_ID',\n",
       " 'Anonymity',\n",
       " 'Anonymity_9_TEXT',\n",
       " 'codable',\n",
       " 'Interaction',\n",
       " 'Acknowledgement',\n",
       " 'Topic_relevance',\n",
       " 'Reasoning',\n",
       " 'Opinion',\n",
       " 'disagreement',\n",
       " 'Ideologicaldirection',\n",
       " 'Name_calling',\n",
       " 'Vulgarity',\n",
       " 'Attack_reputation',\n",
       " 'Question_Intelligenc',\n",
       " 'All_caps_function',\n",
       " 'Sarcasm_to_criticize',\n",
       " 'Individual_right',\n",
       " 'discrimination',\n",
       " 'Invoke_violence',\n",
       " 'Tone',\n",
       " 'Ideology_REC',\n",
       " 'Namecalling_REC',\n",
       " 'vulgar_REC',\n",
       " 'attackreputation_REC',\n",
       " 'questionIntelli_REC',\n",
       " 'ALLCAPS_REC',\n",
       " 'sarcasm_REC',\n",
       " 'individualright_REC',\n",
       " 'discrimination_REC',\n",
       " 'invokeViolence',\n",
       " 'PrimaryLast',\n",
       " 'filter_$']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ICRdata4c.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7c3c75b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StartDate', 'ID', 'Coder', 'Mark_ID', 'Anonymity', 'codable',\n",
       "       'Interaction', 'Acknowledgement', 'TopicRelevance', 'Reasoning',\n",
       "       'BackgroundInfo', 'Opinion', 'disagreement', 'Ideologicaldirection',\n",
       "       'Name_calling', 'Vulgarity', 'Attack_reputation',\n",
       "       'Question_Intelligenc', 'All_caps_function', 'Sarcasm_to_criticize',\n",
       "       'Individual_right', 'discrimination', 'Invoke_violence', 'Tone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ICRdata6c.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6148a8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incivility variables: ['Name_calling', 'Vulgarity', 'Attack_reputation', 'Question_Intelligenc', 'All_caps_function', 'Sarcasm_to_criticize', 'Individual_right', 'discrimination', 'Invoke_violence']\n"
     ]
    }
   ],
   "source": [
    "#get aggregate concept annotations for each coder and each comment:\n",
    "#['INCIVILITY_DUMMY', 'INTERACTIVITY_DUMMY', 'RATIONALITY_DUMMY', '\n",
    "\n",
    "# Define incivility list and other variables\n",
    "incivility_list = ['Name_calling', 'Vulgarity', 'Attack_reputation', 'Question_Intelligenc', \n",
    "                   'All_caps_function', 'Sarcasm_to_criticize', 'Individual_right', \n",
    "                   'discrimination', 'Invoke_violence']\n",
    "print(\"Incivility variables:\", incivility_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c36f35be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#['INTERACTIVITY_DUMMY', 'RATIONALITY_DUMMY', 'LIBERAL_DUMMY', 'CONSERVATIVE_DUMMY']\n",
    "interactivity_list = ['Acknowledgement']\n",
    "rationality_list = [ 'Reasoning', 'BackgroundInfo'] #does this include 'Evidence'?? -> both Evidence and BackgroundInfo are used in the ICRdata6c dataset, but only Reasoning is used in the ICRdata4c dataset, and the codebook also includes 'evidence'\n",
    "ICRdata4c['INTERACTIVITY_DUMMY'] = ICRdata4c['Acknowledgement'].apply(lambda x: 1 if str(x).startswith('Yes') else 0).astype(int)\n",
    "ICRdata6c['INTERACTIVITY_DUMMY'] = ICRdata6c['Acknowledgement'].apply(lambda x: 1 if str(x).startswith('Yes') else 0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "55f56ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummy variables for the political orientation of the comment:\n",
    "ICRdata4c['LIBERAL_DUMMY']= ICRdata4c.Ideologicaldirection.apply(lambda x: 1 if x == 'Left/Liberal/Democratic' else 0)\n",
    "ICRdata4c['CONSERVATIVE_DUMMY']= ICRdata4c.Ideologicaldirection.apply(lambda x: 1 if x == 'Right/Conservative/Republican' else 0)\n",
    "ICRdata6c['LIBERAL_DUMMY']= ICRdata6c.Ideologicaldirection.apply(lambda x: 1 if x == 'Left/Liberal/Democratic' else 0)\n",
    "ICRdata6c['CONSERVATIVE_DUMMY']= ICRdata6c.Ideologicaldirection.apply(lambda x: 1 if x == 'Right/Conservative/Republican' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdc340b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name_calling            0\n",
       "Vulgarity               0\n",
       "Attack_reputation       0\n",
       "Question_Intelligenc    0\n",
       "All_caps_function       0\n",
       "Sarcasm_to_criticize    0\n",
       "Individual_right        0\n",
       "discrimination          0\n",
       "Invoke_violence         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ICRdata6c.loc[:, incivility_list].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "14b7db02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace any value starting with 'No' with 0 and else with 1:\n",
    "for col in incivility_list:\n",
    "    ICRdata6c.loc[:, col] = ICRdata6c.loc[:, col].apply(lambda x: 1 if str(x).startswith('Yes') else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8babf9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ICRdata6c.loc[:, incivility_list] = ICRdata6c.loc[:, incivility_list].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9e952c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now create the same dummy variables as in ICRdata:\n",
    "ICRdata6c.loc[:, 'INCIVILITY_DUMMY'] = (ICRdata6c.loc[:, incivility_list].sum(axis=1) > 0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c66bd29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning_dum created\n",
      "BackgroundInfo_dum created\n"
     ]
    }
   ],
   "source": [
    "#replace any value starting with 'No' with 0 and else with 1:\n",
    "for col in rationality_list:\n",
    "    ICRdata6c.loc[:, f'{col}_dum'] = (ICRdata6c.loc[:, col].apply(lambda x: 1 if str(x).startswith('Yes') else 0)).astype(int)\n",
    "    print(f'{col}_dum created') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b069946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now create the same dummy variables as in paper:\n",
    "ICRdata6c.loc[:, 'RATIONALITY_DUMMY'] = (ICRdata6c.loc[:, ['Reasoning_dum', 'BackgroundInfo_dum']].sum(axis=1) > 0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d69cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for inter-rater reliability\n",
    "!pip install krippendorff scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "21fde284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for inter-rater reliability\n",
    "import krippendorff\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Function to calculate Brennan-Prediger's Kappa\n",
    "def brennan_prediger_kappa(rater1, rater2):\n",
    "    \"\"\"\n",
    "    Calculate Brennan-Prediger's Kappa (also known as Kappa-BP)\n",
    "    This assumes equal probability for each category (uniform marginals)\n",
    "    \"\"\"\n",
    "    # Calculate observed agreement\n",
    "    po = np.mean(rater1 == rater2)\n",
    "    \n",
    "    # Calculate expected agreement assuming uniform marginals\n",
    "    # For binary coding (0,1), pe = 0.5\n",
    "    n_categories = len(np.unique(np.concatenate([rater1, rater2])))\n",
    "    pe = 1 / n_categories\n",
    "    \n",
    "    # Calculate Brennan-Prediger's Kappa\n",
    "    if pe == 1:\n",
    "        return np.nan\n",
    "    else:\n",
    "        kappa_bp = (po - pe) / (1 - pe)\n",
    "    \n",
    "    return kappa_bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1deeeaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare data for inter-rater reliability using Mark_ID\n",
    "def prepare_irr_data(data, variable, id_col='Mark_ID', coder_col='Coder'):\n",
    "    \"\"\"\n",
    "    Prepare data for inter-rater reliability calculations\n",
    "    Returns ratings from Coder 1 and Coder 2 for the same items (Mark_ID)\n",
    "    \"\"\"\n",
    "    # Get data for each coder\n",
    "    coder1_data = data[data[coder_col] == 'Coder 1'][[id_col, variable]].set_index(id_col)\n",
    "    coder2_data = data[data[coder_col] == 'Coder 2'][[id_col, variable]].set_index(id_col)\n",
    "    \n",
    "    # Find common Mark_IDs coded by both coders\n",
    "    common_ids = coder1_data.index.intersection(coder2_data.index)\n",
    "    \n",
    "    # Get ratings for common items\n",
    "    coder1_ratings = coder1_data.loc[common_ids, variable].values\n",
    "    coder2_ratings = coder2_data.loc[common_ids, variable].values\n",
    "    \n",
    "    print(f\"Variable: {variable}\")\n",
    "    print(f\"Number of items coded by both coders: {len(common_ids)}\")\n",
    "    print(f\"Coder 1 distribution: {np.bincount(coder1_ratings)}\")\n",
    "    print(f\"Coder 2 distribution: {np.bincount(coder2_ratings)}\")\n",
    "    \n",
    "    return coder1_ratings, coder2_ratings, common_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2a59641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate all inter-rater reliability metrics\n",
    "def calculate_irr_metrics(coder1_ratings, coder2_ratings, variable_name):\n",
    "    \"\"\"\n",
    "    Calculate Krippendorff's alpha, Brennan-Prediger's kappa, percent agreement, and prevalence\n",
    "    \"\"\"\n",
    "    # Prepare data for Krippendorff's alpha (needs specific format)\n",
    "    # Krippendorff expects a 2D array where each row is a coder and each column is an item\n",
    "    kripp_data = np.array([coder1_ratings, coder2_ratings])\n",
    "    \n",
    "    # Calculate Krippendorff's Alpha\n",
    "    try:\n",
    "        alpha = krippendorff.alpha(kripp_data, level_of_measurement='nominal')\n",
    "    except:\n",
    "        alpha = np.nan\n",
    "    \n",
    "    # Calculate Brennan-Prediger's Kappa\n",
    "    try:\n",
    "        kappa_bp = brennan_prediger_kappa(coder1_ratings, coder2_ratings)\n",
    "    except:\n",
    "        kappa_bp = np.nan\n",
    "    \n",
    "    # Calculate Percent Agreement\n",
    "    agreement = np.mean(coder1_ratings == coder2_ratings) * 100\n",
    "    \n",
    "    # Calculate Prevalence (proportion of positive cases)\n",
    "    total_ratings = len(coder1_ratings) + len(coder2_ratings)\n",
    "    positive_cases = np.sum(coder1_ratings) + np.sum(coder2_ratings)\n",
    "    prevalence = (positive_cases / total_ratings) * 100\n",
    "    \n",
    "        \n",
    "    return {\n",
    "        'Variable': variable_name,\n",
    "        'N_Items': len(coder1_ratings),\n",
    "        'Krippendorff_Alpha': alpha,\n",
    "        'Brennan_Prediger_Kappa': kappa_bp,\n",
    "        'Percent_Agreement': agreement,\n",
    "        'Occurrence (% of comments)': prevalence\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7f544613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Inter-Rater Reliability Analysis ===\n",
      "\n",
      "\n",
      "--- INCIVILITY_DUMMY ---\n",
      "Variable: INCIVILITY_DUMMY\n",
      "Number of items coded by both coders: 196\n",
      "Coder 1 distribution: [ 86 110]\n",
      "Coder 2 distribution: [ 75 121]\n",
      "Krippendorff's Alpha: 0.6741\n",
      "Brennan-Prediger's Kappa: 0.6837\n",
      "Percent Agreement: 84.18%\n",
      "Occurrence (% of comments): 58.93%\n",
      "--------------------------------------------------\n",
      "\n",
      "--- INTERACTIVITY_DUMMY ---\n",
      "Variable: INTERACTIVITY_DUMMY\n",
      "Number of items coded by both coders: 196\n",
      "Coder 1 distribution: [113  83]\n",
      "Coder 2 distribution: [144  52]\n",
      "Krippendorff's Alpha: 0.5605\n",
      "Brennan-Prediger's Kappa: 0.6020\n",
      "Percent Agreement: 80.10%\n",
      "Occurrence (% of comments): 34.44%\n",
      "--------------------------------------------------\n",
      "\n",
      "--- RATIONALITY_DUMMY ---\n",
      "Variable: RATIONALITY_DUMMY\n",
      "Number of items coded by both coders: 196\n",
      "Coder 1 distribution: [155  41]\n",
      "Coder 2 distribution: [135  61]\n",
      "Krippendorff's Alpha: 0.2333\n",
      "Brennan-Prediger's Kappa: 0.4082\n",
      "Percent Agreement: 70.41%\n",
      "Occurrence (% of comments): 26.02%\n",
      "--------------------------------------------------\n",
      "\n",
      "--- LIBERAL_DUMMY ---\n",
      "Variable: LIBERAL_DUMMY\n",
      "Number of items coded by both coders: 196\n",
      "Coder 1 distribution: [149  47]\n",
      "Coder 2 distribution: [151  45]\n",
      "Krippendorff's Alpha: 0.6883\n",
      "Brennan-Prediger's Kappa: 0.7755\n",
      "Percent Agreement: 88.78%\n",
      "Occurrence (% of comments): 23.47%\n",
      "--------------------------------------------------\n",
      "\n",
      "--- CONSERVATIVE_DUMMY ---\n",
      "Variable: CONSERVATIVE_DUMMY\n",
      "Number of items coded by both coders: 196\n",
      "Coder 1 distribution: [167  29]\n",
      "Coder 2 distribution: [165  31]\n",
      "Krippendorff's Alpha: 0.7645\n",
      "Brennan-Prediger's Kappa: 0.8776\n",
      "Percent Agreement: 93.88%\n",
      "Occurrence (% of comments): 15.31%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Calculate inter-rater reliability for all specified variables\n",
    "variables_to_analyze = ['INCIVILITY_DUMMY', 'INTERACTIVITY_DUMMY', 'RATIONALITY_DUMMY', 'LIBERAL_DUMMY', 'CONSERVATIVE_DUMMY']\n",
    "\n",
    "# Store results\n",
    "irr_results = []\n",
    "\n",
    "print(\"=== Inter-Rater Reliability Analysis ===\\n\")\n",
    "\n",
    "for variable in variables_to_analyze:\n",
    "    print(f\"\\n--- {variable} ---\")\n",
    "    \n",
    "    # Prepare data for this variable\n",
    "    coder1_ratings, coder2_ratings, common_ids = prepare_irr_data(ICRdata6c, variable)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = calculate_irr_metrics(coder1_ratings, coder2_ratings, variable)\n",
    "    irr_results.append(metrics)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Krippendorff's Alpha: {metrics['Krippendorff_Alpha']:.4f}\")\n",
    "    print(f\"Brennan-Prediger's Kappa: {metrics['Brennan_Prediger_Kappa']:.4f}\")\n",
    "    print(f\"Percent Agreement: {metrics['Percent_Agreement']:.2f}%\")\n",
    "    print(f\"Occurrence (% of comments): {metrics['Occurrence (% of comments)']:.2f}%\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e115f670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SUMMARY TABLE ===\n",
      "              Variable  N_Items  Krippendorff_Alpha  Brennan_Prediger_Kappa  \\\n",
      "0     INCIVILITY_DUMMY      196                0.67                    0.68   \n",
      "1  INTERACTIVITY_DUMMY      196                0.56                    0.60   \n",
      "2    RATIONALITY_DUMMY      196                0.23                    0.41   \n",
      "3        LIBERAL_DUMMY      196                0.69                    0.78   \n",
      "4   CONSERVATIVE_DUMMY      196                0.76                    0.88   \n",
      "\n",
      "   Percent_Agreement  Occurrence (% of comments)  \n",
      "0              84.18                       58.93  \n",
      "1              80.10                       34.44  \n",
      "2              70.41                       26.02  \n",
      "3              88.78                       23.47  \n",
      "4              93.88                       15.31  \n"
     ]
    }
   ],
   "source": [
    "# Create a summary table of all results\n",
    "irr_summary = pd.DataFrame(irr_results)\n",
    "print(\"\\n=== SUMMARY TABLE ===\")\n",
    "print(irr_summary.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4728c935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmdiv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
