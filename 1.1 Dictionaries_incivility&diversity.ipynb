{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import regex\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Utility classes and meta info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer:\n",
    "    def tokenize(self, text):\n",
    "        tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "        result = []\n",
    "        word = r\"\\p{letter}\"\n",
    "        for sent in nltk.sent_tokenize(text):\n",
    "            tokens = tokenizer.tokenize(sent)    \n",
    "            tokens = [t.lower() for t in tokens \n",
    "                      if regex.search(word, t)]\n",
    "            result += tokens\n",
    "        return result\n",
    "\n",
    "mytokenizer = MyTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDictionaryMapper():\n",
    "    \n",
    "    def __init__(self, dictionaries, raw_text, diversity=None):\n",
    "        self.dictionaries = dictionaries\n",
    "        self.dictionaries_stemmed = [self.get_stemmed_dictionary(e) for e in self.dictionaries]\n",
    "\n",
    "        self.raw_text = raw_text\n",
    "        self.tokenized = [mytokenizer.tokenize(d) for d in self.raw_text if d is not np.nan]\n",
    "        self.tokenized_stemmed = [[ps.stem(i) for i in x] for x in self.tokenized if x is not np.nan]\n",
    "        self.dict_names = [ 'Dict_Hostility_Ksiazek_2015',\n",
    "                'Dict_Civility_Ksiazek_2015', \n",
    "                'Dict_GoogeProject_OffensiveWords', \n",
    "                'Dict_Incivility_Muddiman',\n",
    "                'Dict_Swearwords_LIWC',\n",
    "                'Dict_HatebaseVocabEN',\n",
    "                'MFD1_conservative', \n",
    "                'MFD1_liberal',\n",
    "                'MFD2_conservative', \n",
    "                'MFD2_liberal']\n",
    "        self.diversity = diversity\n",
    "\n",
    "\n",
    "\n",
    "    def get_stemmed_dictionary(self, e):\n",
    "        return (e[0], [ps.stem(x) for x in e[1]])\n",
    "\n",
    "    def return_token_counts(self, text, d):\n",
    "        return sum([text.count(f) for f in d if isinstance(text, str)] ) \n",
    "\n",
    "    def count_tokens(self):\n",
    "\n",
    "        ''' returns counts based on simple string method .count; probably least sophisticated approach. '''\n",
    "\n",
    "        simple_counts = []\n",
    "        for d in self.dictionaries:\n",
    "            simple_counts.append([ self.return_token_counts(text, d[1]) for text in self.raw_text])\n",
    "        return simple_counts\n",
    "\n",
    "    def apply_dictionary(self, tokens, dictionary):\n",
    "        hits = [ w for w in tokens if w.lower() in dictionary ]\n",
    "        return hits\n",
    "\n",
    "    def get_matches(self):\n",
    "\n",
    "        matches = [[self.apply_dictionary(tokens, d[1] ) for tokens in self.tokenized ] for d in self.dictionaries ]\n",
    "        len_matches = [[len(self.apply_dictionary(tokens, d[1])) for tokens in self.tokenized ] for d in self.dictionaries ]\n",
    "        ratio_matches = [[self.zero_div(len(self.apply_dictionary(tokens, d[1])),len(tokens)) for tokens in self.tokenized ] for d in self.dictionaries ]\n",
    "        \n",
    "        return matches, len_matches, ratio_matches\n",
    "    \n",
    "    def zero_div(self,x,y):\n",
    "        if y == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return x/y\n",
    "        \n",
    "    def get_matches_stemmed(self):\n",
    "\n",
    "        matches =  [[self.apply_dictionary(tokens, d[1] ) for tokens in self.tokenized_stemmed ] for d in self.dictionaries_stemmed ]\n",
    "        len_matches = [[len(self.apply_dictionary(tokens, d[1])) for tokens in self.tokenized_stemmed ] for d in self.dictionaries_stemmed ]\n",
    "        ratio_matches = [[self.zero_div(len(self.apply_dictionary(tokens, d[1])),len(tokens)) for tokens in self.tokenized_stemmed ] for d in self.dictionaries_stemmed ]\n",
    "        \n",
    "        return matches, len_matches, ratio_matches\n",
    "\n",
    "    def presence_concept(self, x):\n",
    "    \n",
    "        '''consider concept presence if keywords occur more than N times. WE MAY HAVE TO CHECK WHICH N WORKS BEST!'''\n",
    "        \n",
    "        N = 0\n",
    "\n",
    "        if x > N:\n",
    "            return 1 \n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def dummy_code_results(self, type=\"notstemmed\"):\n",
    "\n",
    "        if type==\"stemmed\":\n",
    "            matches, len_matches, _ = self.get_matches_stemmed()\n",
    "\n",
    "        elif type ==\"notstemmed\":\n",
    "            matches, len_matches, _ = self.get_matches()\n",
    "\n",
    "        dummy_presence = [[self.presence_concept(x) for x in matches] for matches in len_matches ]\n",
    "\n",
    "        return dummy_presence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dicts = 'data/dictionaries/'\n",
    "\n",
    "incivil_dicts = [ 'Dict_Hostility_Ksiazek_2015.txt',\n",
    "                'Dict_Civility_Ksiazek_2015.txt', \n",
    "                'Dict_GoogeProject_OffensiveWords.txt', \n",
    "                'Dict_Incivility_Muddiman.txt',\n",
    "                'Dict_Swearwords_LIWC.txt',\n",
    "                '2020-04-02_HatebaseVocabEN.csv'] \n",
    "\n",
    "dict_set = []\n",
    "\n",
    "for d in incivil_dicts[:-1]:\n",
    "    with open(f'{path_to_dicts}{d}', mode = 'r') as fi:\n",
    "        data = [line.strip() for line in fi]\n",
    "        fname = d.split('.')[0]\n",
    "        dict_set.append((fname,data))\n",
    "temp = pd.read_csv(f'data/dictionaries/2020-04-02_HatebaseVocabEN.csv',sep=';')\n",
    "HB = [i for i in temp['term'] if str(i) != 'nan']\n",
    "dict_set.append((incivil_dicts[-1].split('.')[0],HB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_MFD(fn = 'Dict_MFD_02.txt'):\n",
    "    with open('data/dictionaries/'+fn,'r') as fi:\n",
    "        lines = fi.read()\n",
    "    MFD_conservative = []\n",
    "    MFD_liberal = []\n",
    "    rows = lines.split('\\n')\n",
    "    for i in range(len(rows)):\n",
    "        row = rows[i].split('\\t')\n",
    "        for j in range(1, min(len(row),4)): #only read the first three dimension\n",
    "            if row[j]:\n",
    "                if int(row[j]) <= 4:\n",
    "                    MFD_liberal.append(row[0])\n",
    "                elif int(row[j]) > 4:\n",
    "                    MFD_conservative.append(row[0])\n",
    "    return MFD_conservative, MFD_liberal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFD1_conservative, MFD1_liberal = read_MFD('Dict_MFD_01.txt')\n",
    "MFD2_conservative, MFD2_liberal = read_MFD('Dict_MFD_02.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data/dictionaries/MFD2_liberal.txt','w')\n",
    "for item in MFD2_liberal:\n",
    "    file.write(item+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFD1_conservative, MFD1_liberal = read_MFD('Dict_MFD_01.txt')\n",
    "MFD2_conservative, MFD2_liberal = read_MFD('Dict_MFD_02.txt')\n",
    "dict_set.extend([('MFD1_conservative', MFD1_conservative),('MFD1_liberal', MFD1_liberal),\n",
    "                ('MFD2_conservative', MFD2_conservative),('MFD2_liberal', MFD2_liberal)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initilize MyDictionaryMapper and run the dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(file_name):\n",
    "    select = pd.read_csv(file_name)[['ID','commentText']]\n",
    "    text_clean = select['commentText']\n",
    "    text_clean[0:5]\n",
    "    \n",
    "    #tokens = [mytokenizer.tokenize(d) for d in text_clean if d is not np.nan]\n",
    "\n",
    "    mydictionarymapper = MyDictionaryMapper(dict_set, text_clean)\n",
    "    #get_simple_counts = mydictionarymapper.count_tokens()\n",
    "\n",
    "    get_matches, _, ratio_matches = mydictionarymapper.get_matches_stemmed()\n",
    "    get_dummy_presence_stemmed = mydictionarymapper.dummy_code_results(type=\"stemmed\") # or switch to \"not stemmed\"\n",
    "    get_dummy_presence_unstemmed = mydictionarymapper.dummy_code_results(type =\"notstemmed\")\n",
    "    \n",
    "    stemmed_dummy_variables = [ 'Dict_Hostility_Ksiazek_2015', 'Dict_Civility_Ksiazek_2015', 'Dict_GoogeProject_OffensiveWords', \n",
    "                'Dict_Incivility_Muddiman', 'Dict_Swearwords_LIWC', 'Dict_HatebaseVocabEN','MFD1_conservative', 'MFD1_liberal', 'MFD2_conservative', 'MFD2_liberal']\n",
    "    stemmed_ratio_variables = ['MFD1_conservative_ratio', 'MFD1_liberal_ratio', 'MFD2_conservative_ratio', 'MFD2_liberal_ratio']\n",
    "    unstemmed_dummy_variables = []\n",
    "    \n",
    "    #incivility / hostility / civility are stemmed\n",
    "    #LIWC / Google Project are unstemmed \n",
    "\n",
    "    dummy_stemmed = pd.DataFrame(get_dummy_presence_stemmed).T\n",
    "    dummy_stemmed.columns = mydictionarymapper.dict_names\n",
    "    dummy_stemmed = dummy_stemmed[stemmed_dummy_variables]\n",
    "    assert len(dummy_stemmed) == len(select) ## make sure these are of equal length\n",
    "\n",
    "    display(dummy_stemmed.head(5))\n",
    "\n",
    "\n",
    "    ratio_stemmed = pd.DataFrame(ratio_matches).T#[stemmed_ratio_variables]\n",
    "    ratio_stemmed.columns = [name+'_ratio' for name in mydictionarymapper.dict_names]\n",
    "    ratio_stemmed = ratio_stemmed[stemmed_ratio_variables]\n",
    "    assert len(ratio_stemmed) == len(select) ## make sure these are of equal length\n",
    "\n",
    "    display(ratio_stemmed.head(5))\n",
    "    \n",
    "    #(Re)Merge stemmed / unstemmed dicts results \n",
    "    dict_merge = pd.concat([dummy_stemmed, ratio_stemmed], axis = 1)\n",
    "\n",
    "    #merge with main dataset\n",
    "    df = pd.concat([dict_merge, select], axis = 1)\n",
    "\n",
    "    df = df.rename(columns = {'Civility_dummy':'Civility_dummy_ZeroS',\n",
    "                        'Rationality_dummy':'Rationality_dummy_ZeroS',\n",
    "                        'Ideology_dummy':'Ideology_dummy_ZeroS',\n",
    "                        'Interactivity_dummy':'Interactivity_dummy_ZeroS'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dict_Hostility_Ksiazek_2015</th>\n",
       "      <th>Dict_Civility_Ksiazek_2015</th>\n",
       "      <th>Dict_GoogeProject_OffensiveWords</th>\n",
       "      <th>Dict_Incivility_Muddiman</th>\n",
       "      <th>Dict_Swearwords_LIWC</th>\n",
       "      <th>Dict_HatebaseVocabEN</th>\n",
       "      <th>MFD1_conservative</th>\n",
       "      <th>MFD1_liberal</th>\n",
       "      <th>MFD2_conservative</th>\n",
       "      <th>MFD2_liberal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dict_Hostility_Ksiazek_2015  Dict_Civility_Ksiazek_2015  \\\n",
       "0                            0                           0   \n",
       "1                            1                           1   \n",
       "2                            0                           1   \n",
       "3                            0                           1   \n",
       "4                            0                           1   \n",
       "\n",
       "   Dict_GoogeProject_OffensiveWords  Dict_Incivility_Muddiman  \\\n",
       "0                                 0                         0   \n",
       "1                                 0                         0   \n",
       "2                                 0                         0   \n",
       "3                                 0                         0   \n",
       "4                                 0                         0   \n",
       "\n",
       "   Dict_Swearwords_LIWC  Dict_HatebaseVocabEN  MFD1_conservative  \\\n",
       "0                     0                     0                  0   \n",
       "1                     0                     0                  0   \n",
       "2                     0                     0                  0   \n",
       "3                     0                     0                  1   \n",
       "4                     0                     0                  0   \n",
       "\n",
       "   MFD1_liberal  MFD2_conservative  MFD2_liberal  \n",
       "0             0                  0             0  \n",
       "1             1                  1             1  \n",
       "2             0                  0             0  \n",
       "3             0                  1             0  \n",
       "4             0                  1             1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFD1_conservative_ratio</th>\n",
       "      <th>MFD1_liberal_ratio</th>\n",
       "      <th>MFD2_conservative_ratio</th>\n",
       "      <th>MFD2_liberal_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.060606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MFD1_conservative_ratio  MFD1_liberal_ratio  MFD2_conservative_ratio  \\\n",
       "0                 0.000000            0.000000                 0.000000   \n",
       "1                 0.000000            0.060606                 0.030303   \n",
       "2                 0.000000            0.000000                 0.000000   \n",
       "3                 0.027778            0.000000                 0.027778   \n",
       "4                 0.000000            0.000000                 0.142857   \n",
       "\n",
       "   MFD2_liberal_ratio  \n",
       "0            0.000000  \n",
       "1            0.060606  \n",
       "2            0.000000  \n",
       "3            0.000000  \n",
       "4            0.142857  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = get_results('data/full_data.csv')\n",
    "results.to_csv('outputs/automated_results/Incivility&Diversity.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
